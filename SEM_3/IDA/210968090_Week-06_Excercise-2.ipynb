{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santhosh Darla\n",
    "## 210968090_IDA_Week-6_Excercise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon_baby.csv.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Check the number of the reviews received for each product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Check the products that have more than 15 reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts().loc[lambda x : x > 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Find any missing review are present or not, If present remove those data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df = df[df.review.notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Clean the data and replace the contractions with their expansions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"a'ight\":\"alright\",\n",
    "\"ain't\":\"are not\",\n",
    "\"amn't\":\"am not\",\n",
    "\"aren't\":\"are not\",\n",
    "\"can't\":\"cannot\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\":\"could have\",\n",
    "\"couldn't\":\"could not\",\n",
    "\"couldn't've\":\"could not have\",\n",
    "\"daren't\":\"dare not\",\n",
    "\"daresn't\":\"dare not\",\n",
    "\"dasn't\":\"dare not\",\n",
    "\"didn't\":\"did not\",\n",
    "\"doesn't\":\"does not\",\n",
    "\"don't\":\"do not\",\n",
    "\"everybody's\":\"everybody is\",\n",
    "\"everyone's\":\"everyone is\",\n",
    "\"giv'n\":\"given\",\n",
    "\"gonna\":\"going to\",\n",
    "\"gon't\":\"go not\", \n",
    "\"gotta\":\"got to\",\n",
    "\"hadn't\":\"had not\",\n",
    "\"had've\":\"had have\",\n",
    "\"hasn't\":\"has not\",\n",
    "\"haven't\":\"have not\",\n",
    "\"he'd\":\"he had\", \n",
    "\"he'll\":\"he will\",\n",
    "\"he's\":\"he is\",\n",
    "\"here's\":\"here is\",\n",
    "\"how'd\":\"how did\",\n",
    "\"how'll\":\"how will\",\n",
    "\"how're\":\"how are\",\n",
    "\"how's\":\"how is\",\n",
    "\"I'd\":\"I had\",\n",
    "\"I'd've\":\"I would have\",\n",
    "\"I'd'nt\":\"I would not\",\n",
    "\"I'd'nt've\":\"I would not have\",\n",
    "\"I'll\":\"I will\",\n",
    "\"I'm\":\"I am\",\n",
    "\"I've\":\"I have\",\n",
    "\"isn't\":\"is not\",\n",
    "\"it'd\":\"it would\",\n",
    "\"it'll\":\"it will\",\n",
    "\"it's\":\"it is\",\n",
    "\"let's\":\"let us\",\n",
    "\"ma'am\":\"madam\",\n",
    "\"mayn't\":\"may not\",\n",
    "\"may've\":\"may have\",\n",
    "\"mightn't\":\"might not\",\n",
    "\"might've\":\"might have\",\n",
    "\"mustn't\":\"must not\",\n",
    "\"mustn't've\":\"must not have\",\n",
    "\"must've\":\"must have\",\n",
    "\"needn't\":\"need not\",\n",
    "\"needn't've\":\"need not have\",\n",
    "\"o'clock\":\"of the clock\",\n",
    "\"oughtn't\":\"ought not\",\n",
    "\"oughtn't've\":\"ought not have\",\n",
    "\"shan't\":\"shall not\",\n",
    "\"she'd\":\"she would\",\n",
    "\"she'll\":\"she will\",\n",
    "\"she's\":\"she is\",\n",
    "\"should've\":\"should have\",\n",
    "\"shouldn't\":\"should not\",\n",
    "\"shouldn't've\":\"should not have\",\n",
    "\"somebody's\":\"somebody is\",\n",
    "\"someone's\":\"someone is\",\n",
    "\"something's\":\"something is\",\n",
    "\"so're\":\"so are\",\n",
    "\"so’s\":\"so is\",\n",
    "\"so’ve\":\"so have\",\n",
    "\"that'll\":\"that will\",\n",
    "\"that're\":\"that are\",\n",
    "\"that's\":\"that is\",\n",
    "\"that'd\":\"that would\",\n",
    "\"there'd\":\"there would\",\n",
    "\"there'll\":\"there will\",\n",
    "\"there're\":\"there are\",\n",
    "\"there's\":\"there is\",\n",
    "\"these're\":\"these are\",\n",
    "\"these've\":\"these have\",\n",
    "\"they'd\":\"they would\",\n",
    "\"they'll\":\"they will\",\n",
    "\"they're\":\"they are\",\n",
    "\"they've\":\"they have\",\n",
    "\"this's\":\"this is\",\n",
    "\"those're\":\"those are\",\n",
    "\"those've\":\"those have\",\n",
    "\"to've\":\"to have\",\n",
    "\"wasn't\":\"was not\",\n",
    "\"we'd\":\"we would\",\n",
    "\"we'd've\":\"we would have\",\n",
    "\"we'll\":\"we will\",\n",
    "\"we're\":\"we are\",\n",
    "\"we've\":\"we have\",\n",
    "\"weren't\":\"were not\",\n",
    "\"what'd\":\"what did\",\n",
    "\"what'll\":\"what will\",\n",
    "\"what're\":\"what are\",\n",
    "\"what's\":\"what is\",\n",
    "\"what've\":\"what have\",\n",
    "\"when's\":\"when is\",\n",
    "\"where'd\":\"where did\",\n",
    "\"where'll\":\"where will\",\n",
    "\"where're\":\"where are\",\n",
    "\"where's\":\"where is\",\n",
    "\"where've\":\"where have\",\n",
    "\"which'd\":\"which would\",\n",
    "\"which'll\":\"which will\",\n",
    "\"which're\":\"which are\",\n",
    "\"which's\":\"which is\",\n",
    "\"which've\":\"which have\",\n",
    "\"who'd\":\"who would\",\n",
    "\"who'd've\":\"who would have\",\n",
    "\"who'll\":\"who will\",\n",
    "\"who're\":\"who are\",\n",
    "\"who's\":\"who is\",\n",
    "\"who've\":\"who have\",\n",
    "\"why'd\":\"why did\",\n",
    "\"why're\":\"why are\",\n",
    "\"why's\":\"why is\",\n",
    "\"won't\":\"will not\",\n",
    "\"would've\":\"would have\",\n",
    "\"wouldn't\":\"would not\",\n",
    "\"wouldn't've\":\"would not have\",\n",
    "\"y'at\":\"you at\",\n",
    "\"yes’m\":\"yes madam\",\n",
    "\"you'd\":\"you would\",\n",
    "\"you'll\":\"you will\",\n",
    "\"you're\":\"you are\",\n",
    "\"you've\":\"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        x = x.replace('\\\\','')\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df['review'] = df['review'].apply(lambda x:cont_to_exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Add the Polarity, length of the review, the word count and average word length of each review.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "df['polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "\n",
    "df['review_len'] = df['review'].apply(lambda x:len(x))\n",
    "\n",
    "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "def get_avg_word_len(x):\n",
    "    words = x.split()\n",
    "    word_len = 0\n",
    "    for word in words:\n",
    "        word_len = word_len + len(word)\n",
    "        \n",
    "    return word_len/len(words) \n",
    "\n",
    "\n",
    "df['avg_word_len'] = df['review'].apply(lambda x: get_avg_word_len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Visualize the distribution of the word count, review length, and polarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].hist(bins=20)\n",
    "plt.xlabel('polarity')\n",
    "plt.ylabel('count')\n",
    "plt.title('Sentiment Polarity Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram for review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['review_len'].hist(bins=20)\n",
    "plt.xlabel('review length')\n",
    "plt.ylabel('count')\n",
    "plt.title('Review Text Length Distribution')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram for word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['word_count'].hist(bins=20)\n",
    "plt.xlabel('word count')\n",
    "plt.ylabel('count')\n",
    "plt.title('Word Count Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Visualize polarity considering the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='rating').polarity.agg([np.mean]).plot()\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('polarity')\n",
    "plt.title('Polarity considering Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Visualize the count of the reviews of each rating available in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='rating').review.count().plot.bar()\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('no. of reviews')\n",
    "plt.title('count of the reviews of each rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. List the Top 20 products based on the polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='polarity', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. Visualize to check whether the review length changes with rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='rating', y='review_len', data=df, ci=None)\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('review length')\n",
    "plt.title('Review Length vs Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11. Visualize the distribution of Top 25 Unigram, Bigram and Trigram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(x, n=25):\n",
    "    vec = CountVectorizer(stop_words='english').fit(x)\n",
    "    bag_of_words = vec.transform(x)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = get_top_n_words(df['review'], 25)\n",
    "common_words\n",
    "df1 = pd.DataFrame(common_words, columns = ['Unigram Text' , 'Count'])\n",
    "\n",
    "df1.set_index('Unigram Text', drop=True, inplace=True)\n",
    "df1.plot.bar()\n",
    "plt.xlabel('unigrams')\n",
    "plt.ylabel('count')\n",
    "plt.title('Unigrams Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_n_bigram(x, n=25):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x)\n",
    "    bag_of_words = vec.transform(x)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = get_top_n_bigram(df['review'], 25)\n",
    "common_words\n",
    "df1 = pd.DataFrame(common_words, columns = ['Bigram Text' , 'Count'])\n",
    "\n",
    "df1.set_index('Bigram Text', drop=True, inplace=True)\n",
    "df1.plot.bar()\n",
    "plt.xlabel('bigrams')\n",
    "plt.ylabel('count')\n",
    "plt.title('BIgrams Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_trigram(x, n=25):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words=\"english\").fit(x)\n",
    "    bag_of_words = vec.transform(x)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = get_top_n_trigram(df['review'], 25)\n",
    "common_words\n",
    "df1 = pd.DataFrame(common_words, columns = ['Trigram Text' , 'Count'])\n",
    "\n",
    "df1.set_index('Trigram Text', drop=True, inplace=True)\n",
    "df1.plot.bar()\n",
    "plt.xlabel('trigrams')\n",
    "plt.ylabel('count')\n",
    "plt.title('Trigrams Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
